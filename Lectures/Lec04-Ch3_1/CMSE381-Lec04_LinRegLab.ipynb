{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Simple Linear Regression\n",
    "## CMSE 381 - Fall 2023\n",
    "## Lecture 4 - Sept 5, 2023\n",
    "\n",
    "In the today's lectures, we are focused on simple linear regression, that is, fitting models of the form \n",
    "$$\n",
    "Y =  \\beta_0 +  \\beta_1 X_1 + \\varepsilon\n",
    "$$\n",
    "In this lab, we will use two different tools for linear regression. \n",
    "- [Scikit learn](https://scikit-learn.org/stable/index.html) is arguably the most used tool for machine learning in python \n",
    "- [Statsmodels](https://www.statsmodels.org) provides many of the statisitcial tests we've been learning in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. A note on datasets and ethics\n",
    "\n",
    "For much of this course, I will follow the labs outlined in the textbook at the end of each section (albeit, translated into python).  However, there are many portions of this book that rely on the `Boston` data set. Although this dataset has been a standard example for a long time, often used for teaching linear regression, it has some major issues with assumptions based around race and housing. An excellent in-depth description of issues in the data set can be found [in this medium post from a few years ago](https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8). More recently, the data set has [marked as deprecated in scikit-learn 1.0](https://twitter.com/ogrisel/status/1442894248488046595), which essentially means that anyone loading it will encounter a warning, and is marked for removal in version 1.2.  For these reasons, we will not be using the dataset in this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As always, we start with our favorite standard imports. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, we will be using the `Diabetes` data set.  while we could download a csv to put in the correct folder yadda yadda yadda, because this is a commonly used test data set, it's available in `scikit-learn` for us to use without any cleanup. Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Notice that this loads in a lot of info into what is essentially a beastly dictionary.\n",
    "print(type(diabetes))\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# But we can immediately get it into a pandas data frame for ease of use as follows \n",
    "diabetes_df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
    "diabetes_df['target'] = pd.Series(diabetes.target)\n",
    "\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the data set \n",
    "\n",
    "Look up the documentation about the dataset here: \n",
    "\n",
    "From https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "- Write a brief description of the data set. \n",
    "- What do the columns `s1` through `s6` correspond to? \n",
    "- Which of the available variables are quantitative? Which are categorical?\n",
    "- What is the `target` that we are trying to predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# 2. Getting familiar with the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in your csv file as a pandas data frame. Save this data frame as `boston`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- your code goes in here! ---#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that worked and you managed to load the file, the following command should show you the top of your data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Do some basic data exploration. How many data points do we have? How many variables do we have? Are there any data points with missing data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Use the seaborn `sns.pairplot` command to look at relationships between the variables. Are there pairs of variables that appear to be related? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# 3. Simple Linear Regression\n",
    "\n",
    "We're now going to fig to a simple linear regression to the models\n",
    "$$\n",
    "\\texttt{target} = \\beta_0 + \\beta_1 \\cdot\\texttt{s1}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\texttt{target} = \\beta_0 + \\beta_1 \\cdot\\texttt{s5}\n",
    "$$\n",
    "where the variables are \n",
    "- $\\texttt{s1}$: tc, total serum cholesterol\n",
    "\n",
    "- $\\texttt{s5}$: ltg, possibly log of serum triglycerides level. \n",
    "\n",
    "Let's start by looking at using `s5` to predict `target`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# sklearn actually likes being handed numpy arrays more than \n",
    "# pandas dataframes, so we'll extract the bits we want and just pass it that. \n",
    "X = diabetes_df['s5'].values\n",
    "X = X.reshape([len(X),1])\n",
    "y = diabetes_df['target'].values\n",
    "y = y.reshape([len(y),1])\n",
    "\n",
    "# This code works by first creating an instance of \n",
    "# the linear regression class\n",
    "reg = LinearRegression()\n",
    "# Then we pass in the data we want it to use to fit.\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the fork, nothing seems to have happened? Well actually, we first created an instance of the regression class, which is just a collection of the model functionality waiting to be trained. When we run the `fit` command with data handed in, it actually figures out the best choice of coefficients for our particular data. Once they're found, we can extract them from the class as follows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can find the intercept and coefficient information \n",
    "# from the regression class as follows.\n",
    "\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "- What is the model using these coefficients? That is, write down the function $\\hat f$ explicitly. \n",
    "- What is the prediction by the model for $\\texttt{s5} = 0.05$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Overlay a plot of your predicted model (your line) on a scatter plot of the data used. Does linear seem like a good assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out there is a bit of a cheap trick for plotting linear regression using seaborn.  This command will actually both run the linear regression (that is, find the required $\\beta_i$'s) and plot it for you. The tradeoff is that this will only work for single variable linear regression; we'll have to work harder when we're doing multi-variable linear regression. They also do not provide any easy way to get the equation of the line out, so this isn't really the best tool to use for anything other than quick and dirty visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First easy version, but hard to get out the parameters....\n",
    "sns.regplot(x = diabetes_df.s5,y = diabetes_df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stop Icon](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Vienna_Convention_road_sign_B2a.svg/180px-Vienna_Convention_road_sign_B2a.svg.png)\n",
    "\n",
    "Great, you got to here! Hang out for a bit, there's more lecture before we go on to the next portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating data \n",
    "Ok, let's run an example like was shown in class where we see the distribution of possible values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's code that decides on my function \n",
    "def myFunc(x, b0=2, b1=5): \n",
    "    return b0 + b1*x\n",
    "\n",
    "\n",
    "# Here's a command that generates 100 random data points from f(x) + epsilon\n",
    "def makeData(n = 100):\n",
    "    X = np.random.uniform(-2,2,n)\n",
    "    y = myFunc(X) + np.random.normal(size = n)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everytime you run this cell, you get slightly different data\n",
    "\n",
    "X,y = makeData()\n",
    "\n",
    "plt.scatter(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which means that every time you run this cell, you get a slightly different choice of coefficients\n",
    "# for the model learned\n",
    "\n",
    "X,y = makeData()\n",
    "X = X.reshape([len(X),1])\n",
    "y = y.reshape([len(y),1])\n",
    "reg = LinearRegression()\n",
    "reg.fit(X,y)\n",
    "print( 'y=' + str(round(reg.coef_[0,0],4)) +  \"x_1 + \" +  str(round(reg.intercept_[0],4)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now, lets just train our linear model lots of times, and collect the resulting coefficients\n",
    "\n",
    "beta0_list = []\n",
    "beta1_list = []\n",
    "for i in range(100):\n",
    "    X,y = makeData()\n",
    "    X = X.reshape([len(X),1])\n",
    "    y = y.reshape([len(y),1])\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X,y)\n",
    "    beta1_list.append(reg.coef_[0,0])\n",
    "    beta0_list.append(reg.intercept_[0])\n",
    "\n",
    "print(beta1_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** \n",
    "Make a histogram of `beta1_list` and separately, `beta0_list`.  What do you notice about the distributions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance in estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the statistical test information, we will use the `statsmodels` package. You can take a look at the documentation here: www.statsmodels.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the code is intentially written to look\n",
    "# more like R than like python, but it still works!\n",
    "# Double check..... the coefficients here should be\n",
    "# about the same as those found by scikit-learn\n",
    "est = smf.ols('target ~ s5', diabetes_df).fit()\n",
    "est.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** What is $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** If we instead use `s1` to predict the target, are $SE(\\hat \\beta_0)$ and $SE(\\hat \\beta_1)$ higher or lower than what you found for the `s5` prediction? Is this reasonable? Try plotting your predictions against scatter plots of the data to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by Dr. Liz Munch, Michigan State University\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e3338d56a43a0108f5ff8ffc1915439f9812d920a0d5bf5d66e4a60c981234a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
